Thanks again for the clear comments and instructions. 
Below we summarized the changes we made.

*Required Changes.
- Please explicitly state the limitations of the current solvers (i.e., clarify the "limited support" mentioned by Reviewer B).
- Reviewer B tried Z3 on the running example, and Z3 works fine. Please give an example that cannot be handled by Z3 (as well as any other tools considered in this paper).

We emphasis that we mean limited supprot in terms of scalablity.
We added a paragraph to refer the readers to our table 3 of experiments. 
Even for very simple examples like this one, our tool is the only one that can handle all traces of checkLuhn corresponding to 2~12 loop unfolding.
Other tools (Z3, CVC4, and Z3Str3) timeout or report unknown or error for at least 4 cases.

We found several examples that Z3Str3 reports incorrect answers in the benchmarks involving str-int conversion (see Table 2).
We also found that Z3 reports incorrect answers in benchmarks involoving str-int conversion in release version 4.7.1 and 4.8.1, and github versions from Dec 30 2019- Mar 16, 2020 (versions 321bad2c8-6ad261e24). But we prefer not to report that because it has been fixed very recently on Mar 18.
The version of Z3 we used in the paper does not give incorrect answer.

Below I put a few concrete examples that the bug of Z3 can be reproduced (try it on, for example, the very recent version of Z3 https://github.com/Z3Prover/z3/commit/6ad261e24).
https://github.com/plfm-iis/trauc_benchmarks/blob/master/full_str_int_unsat/py-conbyte_cvc4/lib_int-wsgiref_check_status/0.smt2
https://github.com/plfm-iis/trauc_benchmarks/blob/master/full_str_int_unsat/py-conbyte_trauc/leetcode_int-numDecodings/100.smt2
https://github.com/plfm-iis/trauc_benchmarks/blob/master/full_str_int_unsat/py-conbyte_trauc/leetcode_int-numDecodings/138.smt2

*Recommended Changes.
- Please clarify a bit more about the diversity of the Leetcode programs used in the evaluation.

We added a paragraph in Section 9 to explain it.

- One reviewer actually ran the z3-trau tool on the motivating example. It returns an incorrect result. It would be beneficial to compare against z3-trau in the experiment (and mark all the "incorrect" results).

Z3-trau is the official name of Z3-PFA, which was created for the double-blind requirement. The tool is still under fast development. We guess maybe the reviewer tried some unstable version where bugs are indeed possible. The bug does not exist in our submitted version. Nevertheless we do found 2 instances (out of 53227 cases) that submitted version of Z3-trau reports incorrect results after dividing them into finer categories. It would be very grateful if the reviewers allow us to update the results using a more recently version of Z3-trau.

*Suggested Changes
- Suggestions mentioned in the review comments.

- We have updated the tables of the experiments to unfold the X cases into three categories: incorrect, (system) error, and timeout.
- We have addressed a number of minor comments by reviewers 
(including e.g. a reference to PASS or a note on the assumed decimal encoding of numerals in a reaction to reviewer C) 
and fixed typos pointed out by them.




